{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4 - Multi-Class Classification \n",
    "\n",
    "Nishchay Patel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('performance.csv')\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "getting_count = data[\"Target\"]\n",
    "\n",
    "label_counts = getting_count.value_counts()\n",
    "print(\"Label Distribution:\")\n",
    "print(label_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.strip()\n",
    "data.columns = data.columns.str.replace(' ', '_')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['Target'])\n",
    "\n",
    "X = data.drop('Target', axis=1)\n",
    "\n",
    "categorical_columns_nominal = ['Gender', 'Merit_Scholarship', 'Uni_Transport', 'Learn_Mode', 'Smartphone', 'PC', 'Program', 'Skills1', 'Interest_Area1']\n",
    "categorical_columns_ordinal = ['Eng_Proficiency', 'Relationship']\n",
    "\n",
    "numerical_columns = ['Age', 'Adm_Year', 'HSC_Pass_Year', 'Curr_Sem1', 'Study_Hours1', \n",
    "                     'Study_Sessions1', 'SM_Hours1', 'Avg_Attendance1', 'Skill_Dev_Hours1', \n",
    "                     'Prev_SGPA1', 'Curr_CGPA1', 'Completed_Credits1', 'Family_Income1']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_nominal', OneHotEncoder(drop='first'), categorical_columns_nominal),\n",
    "        ('num', StandardScaler(), numerical_columns)\n",
    "    ])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dense = X_train.toarray()\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_dense)\n",
    "\n",
    "X_train_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test_dense)\n",
    "\n",
    "X_test_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.DataFrame(y_train, columns=['Target'])\n",
    "y_test_df = pd.DataFrame(y_test, columns=['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_df.shape,y_train_df.shape)\n",
    "print(X_test_df.shape,y_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model Training and First Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "log_reg = LogisticRegression(solver='saga', random_state=0)\n",
    "log_reg.fit(X_train_df, y_train_df)\n",
    "\n",
    "svm = SVC(kernel='rbf', random_state=0)\n",
    "svm.fit(X_train_df, y_train_df)\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(X_train_df, y_train_df)\n",
    "\n",
    "log_reg_pred = log_reg.predict(X_test_df)\n",
    "svm_pred = svm.predict(X_test_df)\n",
    "mlp_pred = mlp.predict(X_test_df)\n",
    "\n",
    "log_reg_accuracy = accuracy_score(y_test_df, log_reg_pred)\n",
    "svm_accuracy = accuracy_score(y_test_df, svm_pred)\n",
    "mlp_accuracy = accuracy_score(y_test_df, mlp_pred)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \", log_reg_accuracy)\n",
    "print(\"Support Vector Machine Accuracy: \", svm_accuracy)\n",
    "print(\"MLP Classifier Accuracy: \", mlp_accuracy)\n",
    "\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test_df, log_reg_pred))\n",
    "\n",
    "print(\"\\nSupport Vector Machine Classification Report:\")\n",
    "print(classification_report(y_test_df, svm_pred))\n",
    "\n",
    "print(\"\\nMLP Classifier Classification Report:\")\n",
    "print(classification_report(y_test_df, mlp_pred))\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"], yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"])\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test_df, log_reg_pred, \"Logistic Regression\")\n",
    "plot_confusion_matrix(y_test_df, svm_pred, \"Support Vector Machine\")\n",
    "plot_confusion_matrix(y_test_df, mlp_pred, \"MLP Classifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "param_grid_log_reg_svm = {'C': [0.01, 0.1, 1, 10, 20, 50, 100]}\n",
    "\n",
    "param_grid_mlp = {'hidden_layer_sizes': [(128,), (64, 64), (128, 64), (128, 64, 32)]}\n",
    "\n",
    "log_reg = LogisticRegression(solver='saga', random_state=0)\n",
    "svm = SVC(kernel='rbf', random_state=0)\n",
    "\n",
    "grid_search_log_reg = GridSearchCV(log_reg, param_grid_log_reg_svm, cv=10, scoring='accuracy')\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_log_reg_svm, cv=10, scoring='accuracy')\n",
    "\n",
    "y_train_1d = y_train_df.values.ravel()\n",
    "y_test_1d = y_test_df.values.ravel()\n",
    "\n",
    "grid_search_log_reg.fit(X_train_df, y_train_1d)\n",
    "grid_search_svm.fit(X_train_df, y_train_1d)\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "\n",
    "grid_search_mlp = GridSearchCV(mlp, param_grid_mlp, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search_mlp.fit(X_train_df, y_train_1d)\n",
    "\n",
    "\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_log_reg.best_params_)\n",
    "print(\"Best cross-validation accuracy for Logistic Regression: \", grid_search_log_reg.best_score_)\n",
    "\n",
    "print(\"Best parameters for SVM: \", grid_search_svm.best_params_)\n",
    "print(\"Best cross-validation accuracy for SVM: \", grid_search_svm.best_score_)\n",
    "\n",
    "print(\"Best parameters for MLP: \", grid_search_mlp.best_params_)\n",
    "print(\"Best cross-validation accuracy for MLP: \", grid_search_mlp.best_score_)\n",
    "\n",
    "\n",
    "best_log_reg = grid_search_log_reg.best_estimator_\n",
    "log_reg_pred = best_log_reg.predict(X_test_df)\n",
    "log_reg_accuracy = accuracy_score(y_test_1d, log_reg_pred)\n",
    "print(\"Logistic Regression Test Accuracy: \", log_reg_accuracy)\n",
    "\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "svm_pred = best_svm.predict(X_test_df)\n",
    "svm_accuracy = accuracy_score(y_test_1d, svm_pred)\n",
    "print(\"SVM Test Accuracy: \", svm_accuracy)\n",
    "\n",
    "best_mlp = grid_search_mlp.best_estimator_\n",
    "mlp_pred = best_mlp.predict(X_test_df)\n",
    "mlp_accuracy = accuracy_score(y_test_1d, mlp_pred)\n",
    "print(\"MLP Test Accuracy: \", mlp_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Model Retraining and Second Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "best_log_reg = LogisticRegression(solver='saga', C=grid_search_log_reg.best_params_['C'], random_state=0)\n",
    "best_log_reg.fit(X_train_df, y_train_df)\n",
    "\n",
    "best_svm = SVC(kernel='rbf', C=grid_search_svm.best_params_['C'], random_state=0)\n",
    "best_svm.fit(X_train_df, y_train_df)\n",
    "\n",
    "best_mlp = MLPClassifier(hidden_layer_sizes=grid_search_mlp.best_params_['hidden_layer_sizes'], random_state=0)\n",
    "best_mlp.fit(X_train_df, y_train_df)\n",
    "\n",
    "\n",
    "log_reg_pred = best_log_reg.predict(X_test_df)\n",
    "log_reg_accuracy = accuracy_score(y_test_df, log_reg_pred)\n",
    "log_reg_class_report = classification_report(y_test_df, log_reg_pred)\n",
    "\n",
    "svm_pred = best_svm.predict(X_test_df)\n",
    "svm_accuracy = accuracy_score(y_test_df, svm_pred)\n",
    "svm_class_report = classification_report(y_test_df, svm_pred)\n",
    "\n",
    "mlp_pred = best_mlp.predict(X_test_df)\n",
    "mlp_accuracy = accuracy_score(y_test_df, mlp_pred)\n",
    "mlp_class_report = classification_report(y_test_df, mlp_pred)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression - Test Accuracy:\", log_reg_accuracy)\n",
    "print(\"Logistic Regression - Classification Report:\\n\", log_reg_class_report)\n",
    "\n",
    "print(\"SVM - Test Accuracy:\", svm_accuracy)\n",
    "print(\"SVM - Classification Report:\\n\", svm_class_report)\n",
    "\n",
    "print(\"MLP - Test Accuracy:\", mlp_accuracy)\n",
    "print(\"MLP - Classification Report:\\n\", mlp_class_report)\n",
    "\n",
    "\n",
    "log_reg_cm = confusion_matrix(y_test_df, log_reg_pred)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(log_reg_cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Logistic Regression Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "svm_cm = confusion_matrix(y_test_df, svm_pred)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"SVM Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "mlp_cm = confusion_matrix(y_test_df, mlp_pred)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(mlp_cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"MLP Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6 Analysis and Discussion\n",
    "\n",
    "Performance Comparison Analysis\n",
    "----\n",
    "Before Hyperparameter Tuning\n",
    "\n",
    "Logistic Regression: 75.25%\n",
    "\n",
    "SVM: 76.90%\n",
    "\n",
    "MLP: 74.59%\n",
    "\n",
    "After Hyperparameter Tuning\n",
    "----\n",
    "Logistic Regression: 75.25% (unchanged)\n",
    "\n",
    "SVM: 77.56% (improved by 0.66%)\n",
    "\n",
    "MLP: 76.90% (improved by 2.31%)\n",
    "\n",
    "Model Performance Analysis\n",
    "----\n",
    "Best Performing Model\n",
    "\n",
    "SVM consistently performed the best, both before and after tuning\n",
    "\n",
    "The improvements from hyperparameter tuning were minimal, suggesting the models were already well-configured for the dataset\n",
    "\n",
    "Class-wise Performance\n",
    "----\n",
    "Class 3 shows the highest performance across all models (88-90% precision)\n",
    "\n",
    "Class 1 shows the most inconsistent performance across models\n",
    "\n",
    "Classes 0 and 2 show moderate performance (55-75% range)\n",
    "\n",
    "Possible Reason\n",
    "----\n",
    "1. Class Imbalance\n",
    "\n",
    "    Class 3 has 153 samples\n",
    "\n",
    "    Class 1 has only 12 samples\n",
    "\n",
    "    This significant imbalance affects model learning\n",
    "\n",
    "2. Feature Representation\n",
    "\n",
    "    Classes 0 and 1 might have overlapping features\n",
    "\n",
    "    The models struggle to find clear decision boundaries for these classes\n",
    "\n",
    "3. Data Quality\n",
    "\n",
    "    The small sample size for Class 1 might not capture all possible variations\n",
    "\n",
    "    Features might not be discriminative enough for certain classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "log_reg = LogisticRegression(solver='saga', random_state=0)\n",
    "log_reg.fit(X_train_df, y_train_df)\n",
    "\n",
    "svm = SVC(kernel='rbf', random_state=0)\n",
    "svm.fit(X_train_df, y_train_df)\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(X_train_df, y_train_df)\n",
    "\n",
    "log_reg_pred = log_reg.predict(X_test_df)\n",
    "svm_pred = svm.predict(X_test_df)\n",
    "mlp_pred = mlp.predict(X_test_df)\n",
    "\n",
    "log_reg_accuracy = accuracy_score(y_test_df, log_reg_pred)\n",
    "svm_accuracy = accuracy_score(y_test_df, svm_pred)\n",
    "mlp_accuracy = accuracy_score(y_test_df, mlp_pred)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: \", log_reg_accuracy)\n",
    "print(\"Support Vector Machine Accuracy: \", svm_accuracy)\n",
    "print(\"MLP Classifier Accuracy: \", mlp_accuracy)\n",
    "\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test_df, log_reg_pred))\n",
    "\n",
    "print(\"\\nSupport Vector Machine Classification Report:\")\n",
    "print(classification_report(y_test_df, svm_pred))\n",
    "\n",
    "print(\"\\nMLP Classifier Classification Report:\")\n",
    "print(classification_report(y_test_df, mlp_pred))\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"], yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"])\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test_df, log_reg_pred, \"Logistic Regression\")\n",
    "plot_confusion_matrix(y_test_df, svm_pred, \"Support Vector Machine\")\n",
    "plot_confusion_matrix(y_test_df, mlp_pred, \"MLP Classifier\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
